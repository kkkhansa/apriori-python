{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4CqTbB_4xKC"
      },
      "source": [
        "# LMC-Apriori Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVQ_bY5sZX3F"
      },
      "source": [
        "## Penjelasan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UuaqHgqU-03"
      },
      "source": [
        "Algoritma Apriori adalah teknik dalam data mining yang digunakan untuk menemukan pola hubungan atau association rules di antara item dalam dataset yang besar. Algoritma ini paling sering digunakan untuk analisis keranjang belanja atau market basket analysis di bidang retail. Algoritma ini memiliki beberapa kekurangan, seperti kompleksitas dalam pemfilteran set kandidat dan proses perbandingan yang berulang. LMC-Apriori memanfaatkan pendekatan \"packet pruning\" untuk mengurangi jumlah pencarian yang diperlukan dalam lapisan data, sehingga meningkatkan efisiensi secara signifikan dalam situasi dengan variasi besar antar kelompok data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyMjaFz6VG-E"
      },
      "source": [
        "Aspek utama dari algoritma LMC-Apriori :\n",
        "\n",
        "- Pengelompokan Paket: Memisahkan kumpulan data berdasarkan elemen minimum yang sama, kemudian mengurutkan dan memfilter paket berdasarkan kriteria tertentu.\n",
        "- Penghilangan (Pruning): Mengurangi kompleksitas pencarian dengan mengeliminasi kandidat yang tidak memenuhi syarat frekuensi.\n",
        "- Efisiensi dalam Traversal Data: Memastikan algoritma lebih cepat pada data skala besar dengan traversal yang lebih sedikit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOUzZ7GE_QFi"
      },
      "source": [
        "## Kode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O25CmNO8ZhVv"
      },
      "source": [
        "### Algoritma Kode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LuvBmRHZkKP"
      },
      "source": [
        "1. Inisialisasi Data dan Parameter\n",
        "- Pertama, inisialisasi data transaksi dari file input, lalu tetapkan nilai minimum support (minSup) dan confidence (minConf).\n",
        "- Data transaksi disiapkan sebagai struktur data yang mudah diakses (dictionary transList) dan menghitung frekuensi awal dari setiap item individu di dataset (freqList)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q5UmFFDZ5aN"
      },
      "source": [
        "2. Pencarian Frequent Itemset (genAssociations)\n",
        "- Langkah Pertama (First Pass): Temukan item tunggal (1-itemset) yang memenuhi ambang batas support.\n",
        "\n",
        "  - Untuk setiap item tunggal, hitung nilai support (yaitu proporsi transaksi yang mengandung item tersebut).\n",
        "  - Jika nilai support memenuhi ambang batas minSup, item tersebut dianggap sebagai frequent itemset 1-itemset.\n",
        "\n",
        "- Iterasi dan Generasi Kandidat Itemset:\n",
        "  - Algoritme bekerja secara iteratif, mulai dari itemset 1-itemset, lalu mencari 2-itemset, 3-itemset, dan seterusnya.\n",
        "  - Pada setiap iterasi ke-k, algoritme menggabungkan itemset dari iterasi sebelumnya (k-1-itemset) untuk membentuk kandidat k-itemset baru.\n",
        "  - Algoritme kemudian menghitung support untuk setiap kandidat k-itemset.\n",
        "  - Jika kandidat k-itemset memenuhi support minimum, kandidat tersebut dianggap sebagai frequent itemset dan disimpan.\n",
        "  - Proses ini berulang hingga tidak ada lagi kandidat itemset yang memenuhi ambang batas.\n",
        "\n",
        "- Pruning dan Skyline Reduction:\n",
        "  - Pruning: Algoritme menghapus itemset yang tidak memenuhi ambang batas support.\n",
        "  - Skyline Reduction: Menghilangkan subset dari itemset yang lebih besar agar hanya menyimpan itemset maksimal yang sering. Hal ini menghindari penyimpanan itemset yang kurang relevan (subset) yang telah diwakili oleh itemset yang lebih besar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50YniKreab73"
      },
      "source": [
        "3. Generasi Kandidat Itemset (candidateGen)\n",
        "- Kandidat itemset baru dibentuk dengan menggabungkan itemset yang sering dari iterasi sebelumnya.\n",
        "- Setiap kandidat diperiksa apakah memiliki subset yang juga merupakan itemset yang sering. Kandidat yang tidak memenuhi syarat ini dibuang.\n",
        "- Algoritme ini memastikan hanya kandidat itemset yang relevan yang dihitung frekuensinya dalam dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQoO0UeHakuu"
      },
      "source": [
        "4. Menghasilkan Association Rules (genRules)\n",
        "- Setelah menemukan semua frequent itemsets, algoritme menghasilkan association rules.\n",
        "- Untuk setiap frequent itemset yang terdiri dari 2 item atau lebih, algoritme membuat aturan asosiasi dengan membagi itemset menjadi antecedent (sebelum aturan) dan consequent (setelah aturan).\n",
        "- Menghitung Confidence: Algoritme menghitung confidence untuk setiap aturan.\n",
        "  - Confidence adalah rasio antara support dari keseluruhan itemset dengan support dari subset (antecedent).\n",
        "- Jika confidence memenuhi ambang batas minConf, aturan disimpan sebagai aturan asosiasi yang signifikan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amiVtZa_ZuaE"
      },
      "source": [
        "5. Output dan Tampilan Hasil\n",
        "- Setelah semua frequent itemsets dan aturan asosiasi dihasilkan, hasilnya dicetak.\n",
        "- Fungsi readable() digunakan untuk menampilkan itemset dan aturan asosiasi dalam format yang lebih mudah dibaca."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sUqmPyEl-hT"
      },
      "source": [
        "Di bawah ini adalah contoh kode algoritma LMC-Apriori pada studi kasus transaksi toko roti yang diambil dari https://github.com/timothyasp/apriori-python.git dengan beberapa penyesuaian agar dapat dijalankan menggunakan python 3.0 dan Google Collab. Data yang digunakan adalah data transaksi sebanyak 1000, dengan item berjumlah 49 macam. Jenis item dapat dilihat dalam file goods.csv. Dalam kode di bawah ini, penentuan *association rules* didasarkan pada id item dalam dataset 1000-out1.csv. Adapun kode di bawah juga dapat diimplementasikan kepada dataset yang berukuran lebih besar, seperti 2000 data transaksi (2000-out1.csv), 5000 data transaksi (5000-out1.csv), maupun 10000 data transaksi (10000-out1.csv).\n",
        "\n",
        "Untuk menjalankan kode di bawah, dibutuhkan *file* tambahan yaitu dataset transaksi dan data item yang berupa csv. Kedua *file* ini dapat diakses di https://github.com/timothyasp/apriori-python.git."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iue-5WjtpYiN",
        "outputId": "b97d3411-9d6e-494e-9895-f91c8d3f517d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1, 7, 15, 44, 49\n",
            "2, 1, 19\n",
            "3, 1, 19\n",
            "4, 3, 4, 15, 18, 35, 44\n",
            "5, 2, 4, 7, 9, 23\n",
            "6, 14, 21, 44\n",
            "7, 4, 12, 31, 36, 44, 48\n",
            "8, 15, 27, 28\n",
            "9, 2, 28\n",
            "10, 3, 18, 35\n"
          ]
        }
      ],
      "source": [
        "# Menunjukkan dataset transaksi\n",
        "!head -n 10 data/1000/1000-out1.csv # dapat diubah sesuai dengan nama file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv5zCtzMppQL",
        "outputId": "bde60a65-9c56-4e34-cb18-0603c157ac6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0,'Chocolate','Cake',8.95,'Food'\n",
            "1,'Lemon','Cake',8.95,'Food'\n",
            "2,'Casino','Cake',15.95,'Food'\n",
            "3,'Opera','Cake',15.95,'Food'\n",
            "4,'Strawberry','Cake',11.95,'Food'\n",
            "5,'Truffle','Cake',15.95,'Food'\n",
            "6,'Chocolate','Eclair',3.25,'Food'\n",
            "7,'Coffee','Eclair',3.5,'Food'\n",
            "8,'Vanilla','Eclair',3.25,'Food'\n",
            "9,'Napoleon','Cake',13.49,'Food'\n"
          ]
        }
      ],
      "source": [
        "# Menunjukkan dataset item\n",
        "!head -n 10 goods.csv # dapat diubah sesuai dengan nama file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBwbrRaS_1zg",
        "outputId": "b508edb5-15ef-4bc2-9eea-6b15c560e043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset:  data/1000/1000-out1.csv  MinSup:  0.03  MinConf:  0.7\n",
            "==================================================================\n",
            "1 :   Gongolais Cookie (22),\tTruffle Cake (5) \tsupport= 0.058\n",
            "2 :   Marzipan Cookie (27),\tTuile Cookie (28) \tsupport= 0.053\n",
            "3 :   Lemon Cookie (24),\tRaspberry Lemonade (41) \tsupport= 0.03\n",
            "4 :   Apricot Croissant (32),\tHot Coffee (45) \tsupport= 0.032\n",
            "5 :   Casino Cake (2),\tChocolate Coffee (46) \tsupport= 0.039\n",
            "6 :   Cheese Croissant (33),\tOrange Juice (42) \tsupport= 0.038\n",
            "7 :   Lemon Cookie (24),\tLemon Lemonade (40) \tsupport= 0.031\n",
            "8 :   Almond Twist (37),\tCoffee Eclair (7) \tsupport= 0.03\n",
            "9 :   Chocolate Cake (0),\tChocolate Coffee (46) \tsupport= 0.047\n",
            "10 :   Strawberry Cake (4),\tNapoleon Cake (9) \tsupport= 0.049\n",
            "11 :   Raspberry Cookie (23),\tLemon Lemonade (40) \tsupport= 0.031\n",
            "12 :   Blueberry Tart (16),\tHot Coffee (45) \tsupport= 0.033\n",
            "13 :   Cherry Tart (18),\tOpera Cake (3) \tsupport= 0.041\n",
            "14 :   Hot Coffee (45),\tApricot Croissant (32),\tBlueberry Tart (16) \tsupport= 0.032\n",
            "15 :   Chocolate Coffee (46),\tChocolate Cake (0),\tCasino Cake (2) \tsupport= 0.038\n",
            "16 :   Apple Tart (12),\tApple Croissant (31),\tApple Danish (36),\tCherry Soda (48) \tsupport= 0.031\n",
            "17 :   Apple Tart (12),\tApple Croissant (31),\tCherry Soda (48),\tApple Danish (36) \tsupport= 0.031\n",
            "Skyline Itemsets:  17\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os.path\n",
        "import csv\n",
        "import math\n",
        "import types\n",
        "from collections import defaultdict\n",
        "from collections.abc import Iterable\n",
        "import itertools\n",
        "\n",
        "# Kelas Apriori untuk menemukan frequent itemset dan menghasilkan aturan asosiasi\n",
        "class Apriori:\n",
        "    def __init__(self, data, minSup, minConf):\n",
        "        # Inisialisasi variabel utama\n",
        "        self.dataset = data\n",
        "        self.transList = defaultdict(list)  # Menyimpan daftar transaksi\n",
        "        self.freqList = defaultdict(int)  # Menyimpan frekuensi item\n",
        "        self.itemset = set()  # Menyimpan item yang unik\n",
        "        self.highSupportList = list()  # Menyimpan item dengan support tinggi\n",
        "        self.numItems = 0  # Total jumlah item\n",
        "        self.prepData()  # Menyiapkan data transaksi\n",
        "\n",
        "        self.F = defaultdict(list)  # Menyimpan frequent itemset\n",
        "\n",
        "        self.minSup = minSup  # Nilai minimum support\n",
        "        self.minConf = minConf  # Nilai minimum confidence\n",
        "\n",
        "    # Menghasilkan asosiasi untuk frequent itemset\n",
        "    def genAssociations(self):\n",
        "        candidate = {}\n",
        "        count = {}\n",
        "\n",
        "        # Pemindaian pertama untuk menemukan item satu-item yang sering\n",
        "        self.F[1] = self.firstPass(self.freqList, 1)\n",
        "        k = 2\n",
        "        while len(self.F[k-1]) != 0:  # Iterasi hingga tidak ada lagi frequent itemset\n",
        "            candidate[k] = self.candidateGen(self.F[k-1], k)  # Menghasilkan kandidat itemset\n",
        "            # Menghitung frekuensi setiap kandidat pada data transaksi\n",
        "            for t in self.transList.items():\n",
        "                for c in candidate[k]:\n",
        "                    if set(c).issubset(t[1]):\n",
        "                        self.freqList[c] += 1\n",
        "\n",
        "            self.F[k] = self.prune(candidate[k], k)  # Menghapus itemset yang tidak memenuhi syarat\n",
        "            if k > 2:\n",
        "                self.removeSkyline(k, k-1)  # Menghilangkan subset yang tidak perlu\n",
        "            k += 1\n",
        "\n",
        "        return self.F\n",
        "\n",
        "    # Menghapus subset yang tidak perlu dari frequent itemset\n",
        "    def removeSkyline(self, k, kPrev):\n",
        "        for item in self.F[k]:\n",
        "            subsets = self.genSubsets(item)\n",
        "            for subset in subsets:\n",
        "                if subset in self.F[kPrev]:\n",
        "                    self.F[kPrev].remove(subset)\n",
        "\n",
        "    # Memfilter itemset berdasarkan nilai support\n",
        "    def prune(self, items, k):\n",
        "        f = []\n",
        "        for item in items:\n",
        "            count = self.freqList[item]\n",
        "            support = self.support(count)\n",
        "            # Jika support >= 0.95, tambahkan ke daftar highSupportList\n",
        "            if support >= .95:\n",
        "                self.highSupportList.append(item)\n",
        "            # Jika memenuhi minimum support, tambahkan ke frequent itemset\n",
        "            elif support >= self.minSup:\n",
        "                f.append(item)\n",
        "\n",
        "        return f\n",
        "\n",
        "    # Menghasilkan kandidat itemset dengan menggabungkan itemset sebelumnya\n",
        "    def candidateGen(self, items, k):\n",
        "        candidate = []\n",
        "\n",
        "        if k == 2:\n",
        "            # Menggabungkan dua item jika panjangnya dua\n",
        "            candidate = [tuple(sorted([x, y])) for x in items for y in items if len((x, y)) == k and x != y]\n",
        "        else:\n",
        "            # Menggabungkan itemset yang lebih besar\n",
        "            candidate = [tuple(set(x).union(y)) for x in items for y in items if len(set(x).union(y)) == k and x != y]\n",
        "\n",
        "        # Memfilter kandidat yang tidak memenuhi syarat\n",
        "        for c in candidate:\n",
        "            subsets = self.genSubsets(c)\n",
        "            if any([x not in items for x in subsets]):\n",
        "                candidate.remove(c)\n",
        "\n",
        "        return set(candidate)\n",
        "\n",
        "    # Menghasilkan semua subset dari suatu itemset\n",
        "    def genSubsets(self, item):\n",
        "        subsets = []\n",
        "        for i in range(1, len(item)):\n",
        "            subsets.extend(itertools.combinations(item, i))\n",
        "        return subsets\n",
        "\n",
        "    # Menghasilkan aturan asosiasi dari frequent itemset\n",
        "    def genRules(self, F):\n",
        "        H = []\n",
        "\n",
        "        for k, itemset in F.items():\n",
        "            if k >= 2:\n",
        "                for item in itemset:\n",
        "                    subsets = self.genSubsets(item)\n",
        "                    for subset in subsets:\n",
        "                        # Mendapatkan count subset dan item\n",
        "                        if len(subset) == 1:\n",
        "                            subCount = self.freqList[subset[0]]\n",
        "                        else:\n",
        "                            subCount = self.freqList[subset]\n",
        "                        itemCount = self.freqList[item]\n",
        "                        # Menghitung confidence dan menambahkan aturan jika memenuhi syarat\n",
        "                        if subCount != 0:\n",
        "                            confidence = self.confidence(subCount, itemCount)\n",
        "                            if confidence >= self.minConf:\n",
        "                                support = self.support(self.freqList[item])\n",
        "                                rhs = self.difference(item, subset)\n",
        "                                if len(rhs) == 1:\n",
        "                                    H.append((subset, rhs, support, confidence))\n",
        "\n",
        "        return H\n",
        "\n",
        "    # Menghitung perbedaan antara item dan subset\n",
        "    def difference(self, item, subset):\n",
        "        return tuple(x for x in item if x not in subset)\n",
        "\n",
        "    # Menghitung nilai confidence dari suatu aturan\n",
        "    def confidence(self, subCount, itemCount):\n",
        "        return float(itemCount) / subCount\n",
        "\n",
        "    # Menghitung nilai support dari suatu itemset\n",
        "    def support(self, count):\n",
        "        return float(count) / self.numItems\n",
        "\n",
        "    # Pemindaian pertama untuk item satu-item yang sering\n",
        "    def firstPass(self, items, k):\n",
        "        f = []\n",
        "        for item, count in items.items():\n",
        "            support = self.support(count)\n",
        "            if support == 1:\n",
        "                self.highSupportList.append(item)\n",
        "            elif support >= self.minSup:\n",
        "                f.append(item)\n",
        "\n",
        "        return f\n",
        "\n",
        "    # Menyiapkan data transaksi menjadi format dictionary\n",
        "    def prepData(self):\n",
        "        key = 0\n",
        "        for basket in self.dataset:\n",
        "            self.numItems += 1\n",
        "            key = basket[0]\n",
        "            for i, item in enumerate(basket):\n",
        "                if i != 0:\n",
        "                    self.transList[key].append(item.strip())\n",
        "                    self.itemset.add(item.strip())\n",
        "                    self.freqList[(item.strip())] += 1\n",
        "\n",
        "# Fungsi utama untuk mengelola input dan memulai algoritma\n",
        "def main():\n",
        "    goods = defaultdict(list)\n",
        "    num_args = len(sys.argv)\n",
        "    minSup = minConf = 0\n",
        "    noRules = False\n",
        "\n",
        "    # Memeriksa jumlah argumen input yang benar\n",
        "    if num_args < 4 or num_args > 5:\n",
        "        print('Expected input format: python apriori.py <dataset.csv> <minSup> <minConf>')\n",
        "        return\n",
        "    elif num_args == 5 and sys.argv[1] == \"--no-rules\":\n",
        "        dataset = csv.reader(open(sys.argv[2], \"r\"))\n",
        "        goodsData = csv.reader(open('goods.csv', \"r\"))\n",
        "        minSup = float(sys.argv[3])\n",
        "        minConf = float(sys.argv[4])\n",
        "        noRules = True\n",
        "        print(\"Dataset: \", sys.argv[2], \" MinSup: \", minSup, \" MinConf: \", minConf)\n",
        "    else:\n",
        "        dataset = csv.reader(open(sys.argv[1], \"r\"))\n",
        "        goodsData = csv.reader(open('goods.csv', \"r\"))\n",
        "        minSup = float(sys.argv[2])\n",
        "        minConf = float(sys.argv[3])\n",
        "        print(\"Dataset: \", sys.argv[1], \" MinSup: \", minSup, \" MinConf: \", minConf)\n",
        "\n",
        "    print(\"==================================================================\")\n",
        "\n",
        "    # Membaca deskripsi item dari goods.csv\n",
        "    for item in goodsData:\n",
        "        goods[item[0]] = item[1:]\n",
        "\n",
        "    # Membuat objek Apriori dan menemukan frequent itemset\n",
        "    a = Apriori(dataset, minSup, minConf)\n",
        "    frequentItemsets = a.genAssociations()\n",
        "\n",
        "    # Menampilkan frequent itemset\n",
        "    count = 0\n",
        "    for k, item in frequentItemsets.items():\n",
        "        for i in item:\n",
        "            if k >= 2:\n",
        "                count += 1\n",
        "                print(count, \":  \", readable(i, goods), \"\\tsupport=\", a.support(a.freqList[i]))\n",
        "\n",
        "    print(\"Skyline Itemsets: \", count)\n",
        "    # Jika aturan diminta, menghasilkan dan menampilkan aturan asosiasi\n",
        "    if not noRules:\n",
        "        rules = a.genRules(frequentItemsets)\n",
        "        for i, rule in enumerate(rules):\n",
        "            print(\"Rule\", i + 1, \":\\t \", readable(rule[0], goods), \"\\t-->\", readable(rule[1], goods), \"\\t [sup=\", rule[2], \" conf=\", rule[3], \"]\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Fungsi untuk menghasilkan format yang lebih mudah dibaca untuk itemset\n",
        "def readable(item, goods):\n",
        "    itemStr = ''\n",
        "    for k, i in enumerate(item):\n",
        "        itemStr += goods[i][0] + \" \" + goods[i][1] + \" (\" + i + \")\"\n",
        "        if len(item) != 0 and k != len(item) - 1:\n",
        "            itemStr += \",\\t\"\n",
        "\n",
        "    return itemStr.replace(\"'\", \"\")\n",
        "'''\n",
        "# Memulai program jika dijalankan sebagai skrip utama\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# Set parameter\n",
        "data_path = 'data/1000/1000-out1.csv' # dapat diubah sesuai dengan file dataset\n",
        "min_sup = 0.03 # dapat diubah sesuai dengan kebutuhan\n",
        "min_conf = 0.7 # dapat diubah sesuai dengan kebutuhan\n",
        "\n",
        "# Call main() with simulated command-line arguments\n",
        "sys.argv = [\"apriori.py\", '--no-rules', data_path, min_sup, min_conf]\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
